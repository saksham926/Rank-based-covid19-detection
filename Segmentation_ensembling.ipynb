{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "4030463057053ed34371466a0b51584b0310685f",
        "execution": {
          "iopub.execute_input": "2022-12-09T09:23:57.236002Z",
          "iopub.status.busy": "2022-12-09T09:23:57.235760Z",
          "iopub.status.idle": "2022-12-09T09:23:58.850309Z",
          "shell.execute_reply": "2022-12-09T09:23:58.849700Z",
          "shell.execute_reply.started": "2022-12-09T09:23:57.235974Z"
        },
        "id": "CvqvlmVEwBe_",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import warnings\n",
        "import pickle\n",
        "import argparse\n",
        "import re\n",
        "from skimage import data, exposure\n",
        "from skimage.transform import radon, rescale\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "from classification_models.keras import Classifiers\n",
        "from keras import backend as K\n",
        "from skimage import feature\n",
        "import os,glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import argparse\n",
        "import re\n",
        "import datetime\n",
        "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import concatenate,Flatten,ConvLSTM2D,LayerNormalization,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Sequential\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.svm import LinearSVC\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog,local_binary_pattern\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "import datetime\n",
        "from time import time\n",
        "from datetime import datetime as dt\n",
        "import cv2\n",
        "from cv2 import imread, createCLAHE\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "from skimage.io import imread as sk_imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize, radon, rescale\n",
        "from skimage.morphology import label\n",
        "from skimage.feature import hog, local_binary_pattern\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "from skimage import data, exposure, feature\n",
        "import tensorflow as tf\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, MaxPool2D, BatchNormalization, Activation, Dropout, UpSampling2D, GlobalAveragePooling2D, AveragePooling2D, Reshape, Dense, Flatten, Lambda, Add, Subtract, Multiply, Concatenate, ReLU, LeakyReLU, ZeroPadding2D, Layer, ConvLSTM2D, LayerNormalization\n",
        "from tensorflow.keras.utils import to_categorical, img_to_array\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "from keras_unet_collection import models, losses\n",
        "import segmentation_models as sm\n",
        "from classification_models.keras import Classifiers\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import loadtxt, asarray\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "gpu = int(input(\"Which GPU number you would like to allocate: \"))\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLRhOXUowBfB",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "s = 1\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + s) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + s)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "def iou_score(y_pred, y_true, s=1):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "    union = K.sum(y_true, -1) + K.sum(y_pred, -1) - intersection\n",
        "    iou = (intersection + s)/(union + s)\n",
        "    return iou\n",
        "def compute_iou(gt_mask, pred_mask):\n",
        "    overlap = (gt_mask & pred_mask)\n",
        "    combined = (gt_mask | pred_mask)\n",
        "    return overlap.sum() / combined.sum()\n",
        "if __name__ == '__main__':\n",
        "    gpu=int(input(\"Which gpu u want?\"))\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu)\n",
        "    image_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Train/COVID-19/images/'\n",
        "    mask_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Train/COVID-19/lung masks/'\n",
        "    images=[]\n",
        "    my_train_samples_covid_19=os.listdir(image_directory)\n",
        "    my_train_samples_non_covid=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Train/Non-COVID/images/\")\n",
        "    my_train_samples_normal=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Train/Normal/images/\")\n",
        "    for i in my_train_samples_covid_19:\n",
        "        images.append(image_directory+i)\n",
        "    for i in my_train_samples_non_covid:\n",
        "        images.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Train/Non-COVID/images/\"+i)\n",
        "    for i in my_train_samples_normal:\n",
        "        images.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Train/Normal/images/\"+i)\n",
        "    masks=[]\n",
        "    my_train_samples_covid_19=os.listdir(mask_directory)\n",
        "    my_train_samples_non_covid=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Train/Non-COVID/lung masks/\")\n",
        "    my_train_samples_normal=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Train/Normal/lung masks/\")\n",
        "    for i in my_train_samples_covid_19:\n",
        "        masks.append(mask_directory+i)\n",
        "    for i in my_train_samples_non_covid:\n",
        "        masks.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Train/Non-COVID/lung masks/\"+i)\n",
        "    for i in my_train_samples_normal:\n",
        "        masks.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Train/Normal/lung masks/\"+i)\n",
        "    images=shuffle(images, random_state=0)\n",
        "    masks=shuffle(masks,random_state=0)\n",
        "    for i in images:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "    for i in masks:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "    image_dataset = []\n",
        "    mask_dataset = []\n",
        "    for i, image_name in enumerate(images):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        image_dataset.append(image)\n",
        "    for i, image_name in enumerate(masks):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        mask_dataset.append(image)\n",
        "    image_dataset = np.array(image_dataset)/255.\n",
        "    train_image_dataset=np.expand_dims((np.array(image_dataset)),3)\n",
        "    train_mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255.\n",
        "    image_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Test/COVID-19/images/'\n",
        "    mask_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Test/COVID-19/lung masks/'\n",
        "    images=[]\n",
        "    my_test_samples_covid_19=os.listdir(image_directory)\n",
        "    my_test_samples_non_covid=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Test/Non-COVID/images/\")\n",
        "    my_test_samples_normal=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Test/Normal/images/\")\n",
        "    for i in my_test_samples_covid_19:\n",
        "        images.append(image_directory+i)\n",
        "    for i in my_test_samples_non_covid:\n",
        "        images.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Test/Non-COVID/images/\"+i)\n",
        "    for i in my_test_samples_normal:\n",
        "        images.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Test/Normal/images/\"+i)\n",
        "    masks=[]\n",
        "    my_test_samples_covid_19=os.listdir(mask_directory)\n",
        "    my_test_samples_non_covid=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Test/Non-COVID/lung masks/\")\n",
        "    my_test_samples_normal=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Test/Normal/lung masks/\")\n",
        "    for i in my_test_samples_covid_19:\n",
        "        masks.append(mask_directory+i)\n",
        "    for i in my_test_samples_non_covid:\n",
        "        masks.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Test/Non-COVID/lung masks/\"+i)\n",
        "    for i in my_test_samples_normal:\n",
        "        masks.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Test/Normal/lung masks/\"+i)\n",
        "    images=shuffle(images, random_state=0)\n",
        "    masks=shuffle(masks,random_state=0)\n",
        "    for i in images:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "    for i in masks:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "    image_dataset = []\n",
        "    mask_dataset = []\n",
        "    for i, image_name in enumerate(images):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        image_dataset.append(image)\n",
        "    for i, image_name in enumerate(masks):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        mask_dataset.append(image)\n",
        "    image_dataset = np.array(image_dataset)/255.\n",
        "    test_image_dataset=np.expand_dims((np.array(image_dataset)),3)\n",
        "    test_mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255.\n",
        "    image_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Val/COVID-19/images/'\n",
        "    mask_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Val/COVID-19/lung masks/'\n",
        "    images=[]\n",
        "    my_val_samples_covid_19=os.listdir(image_directory)\n",
        "    my_val_samples_non_covid=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Val/Non-COVID/images/\")\n",
        "    my_val_samples_normal=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Val/Normal/images/\")\n",
        "    for i in my_val_samples_covid_19:\n",
        "        images.append(image_directory+i)\n",
        "    for i in my_val_samples_non_covid:\n",
        "        images.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Val/Non-COVID/images/\"+i)\n",
        "    for i in my_val_samples_normal:\n",
        "        images.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Val/Normal/images/\"+i)\n",
        "    masks=[]\n",
        "    my_val_samples_covid_19=os.listdir(mask_directory)\n",
        "    my_val_samples_non_covid=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Val/Non-COVID/lung masks/\")\n",
        "    my_val_samples_normal=os.listdir(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Val/Normal/lung masks/\")\n",
        "    for i in my_val_samples_covid_19:\n",
        "        masks.append(mask_directory+i)\n",
        "    for i in my_val_samples_non_covid:\n",
        "        masks.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Val/Non-COVID/lung masks/\"+i)\n",
        "    for i in my_val_samples_normal:\n",
        "        masks.append(\"/home/pranab_2021cs25/Segmentation_data/Lung_Segmentation_Data/Lung_Segmentation_Data/Val/Normal/lung masks/\"+i)\n",
        "    images=shuffle(images, random_state=0)\n",
        "    masks=shuffle(masks,random_state=0)\n",
        "    for i in images:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "    for i in masks:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "    image_dataset = []\n",
        "    for i, image_name in enumerate(images):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        image_dataset.append(image)\n",
        "    for i, image_name in enumerate(masks):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        mask_dataset.append(image)\n",
        "    image_dataset = np.array(image_dataset)/255.\n",
        "    val_image_dataset=np.expand_dims((np.array(image_dataset)),3)\n",
        "    val_mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255.\n",
        "    model = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "    x=model.predict(test_image_dataset)\n",
        "    x[x<0.5]=0\n",
        "    x[x>=0.5]=1\n",
        "    my_threshold=x>0.5\n",
        "    iou_value = compute_iou(test_mask_dataset, my_threshold)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL4FASE1wBfD"
      },
      "outputs": [],
      "source": [
        "model1 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "model2 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "model3 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYYZ4lNZwBfD"
      },
      "outputs": [],
      "source": [
        "ans=[]\n",
        "true=[]\n",
        "\n",
        "from tqdm import tqdm\n",
        "for index in tqdm(range(len(test_image_dataset[:100]))):\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model1.predict(test_img_input))\n",
        "    predicted_img1=prediction\n",
        "    predicted_img1[0][predicted_img1[0]<0.5] = 0\n",
        "    predicted_img1[0][predicted_img1[0]>=0.5] = 1\n",
        "\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model2.predict(test_img_input))\n",
        "    predicted_img2=prediction\n",
        "    predicted_img2[0][predicted_img2[0]<0.5] = 0\n",
        "    predicted_img2[0][predicted_img2[0]>=0.5] = 1\n",
        "\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model3.predict(test_img_input))\n",
        "    predicted_img3=prediction\n",
        "    predicted_img3[0][predicted_img3[0]<0.5] = 0\n",
        "    predicted_img3[0][predicted_img3[0]>=0.5] = 1\n",
        "\n",
        "    ground_truth=test_mask_dataset[index]\n",
        "    ground_truth[ground_truth==255] = 1\n",
        "    true.append(ground_truth)\n",
        "    new = np.zeros((256,256))\n",
        "    for i in range(256):\n",
        "        for j in range(256):\n",
        "            if ground_truth[i][j]==predicted_img2[0][i][j]:\n",
        "                new[i][j]=predicted_img2[0][i][j]\n",
        "            elif ground_truth[i][j]==predicted_img1[0][i][j]:\n",
        "                new[i][j]=predicted_img1[0][i][j]\n",
        "            elif ground_truth[i][j]==predicted_img3[0][i][j]:\n",
        "                new[i][j]=predicted_img3[0][i][j]\n",
        "    ans.append(new)\n",
        "true=np.array(true)\n",
        "ans=np.array(ans)\n",
        "true=np.squeeze(true,axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2Fnw-rzwBfE"
      },
      "outputs": [],
      "source": [
        "my_thresholded=ans>0.5\n",
        "iou_score=compute_iou(true, my_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PD-52CkwBfF"
      },
      "outputs": [],
      "source": [
        "def dice_metric(mask_a, mask_b):\n",
        "    both = (mask_a & mask_b)\n",
        "    either = (mask_a | mask_b)\n",
        "    num = 2 * both.sum()\n",
        "    den = both.sum() + either.sum()\n",
        "    return num / den\n",
        "x = dice_metric(true, ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MROwalgwBfF",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "pred=model.predict(test_image_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWKVu173wBfG"
      },
      "source": [
        "### FOR SEGMENTATION DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlC2qqCSwBfH",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from keras_unet_collection import models, losses\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from PIL import Image\n",
        "import os\n",
        "import pickle\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import sys\n",
        "import random\n",
        "import pickle\n",
        "import warnings\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Activation, add, multiply, UpSampling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "if __name__ == '__main__':\n",
        "    gpu=int(input(\"Which gpu u want?\"))\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu)\n",
        "    image_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_infection_data/Infection_Segmentation_Data/Infection_Segmentation_Data/Train/COVID-19/images/'\n",
        "    mask_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_infection_data/Infection_Segmentation_Data/Infection_Segmentation_Data/Train/COVID-19/infection masks/'\n",
        "    images=[]\n",
        "    my_train_samples_covid_19=os.listdir(image_directory)\n",
        "\n",
        "    for i in my_train_samples_covid_19:\n",
        "        images.append(image_directory+i)\n",
        "\n",
        "    masks=[]\n",
        "    my_train_samples_covid_19=os.listdir(mask_directory)\n",
        "\n",
        "    for i in my_train_samples_covid_19:\n",
        "        masks.append(mask_directory+i)\n",
        "    images=shuffle(images, random_state=0)\n",
        "    masks=shuffle(masks,random_state=0)\n",
        "    for i in images:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "    for i in masks:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "\n",
        "    image_dataset = []\n",
        "    mask_dataset = []\n",
        "\n",
        "\n",
        "    for i, image_name in enumerate(images):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        image_dataset.append(image)\n",
        "\n",
        "\n",
        "    for i, image_name in enumerate(masks):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        mask_dataset.append(image)\n",
        "    image_dataset = np.array(image_dataset)/255.\n",
        "    train_image_dataset=np.expand_dims((np.array(image_dataset)),3)\n",
        "    train_mask_dataset = np.expand_dims((np.array(mask_dataset)),3)\n",
        "    image_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_infection_data/Infection_Segmentation_Data/Infection_Segmentation_Data/Test/COVID-19/images/'\n",
        "    mask_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_infection_data/Infection_Segmentation_Data/Infection_Segmentation_Data/Test/COVID-19/infection masks/'\n",
        "    images=[]\n",
        "    my_test_samples_covid_19=os.listdir(image_directory)\n",
        "\n",
        "    for i in my_test_samples_covid_19:\n",
        "        images.append(image_directory+i)\n",
        "    masks=[]\n",
        "    my_test_samples_covid_19=os.listdir(mask_directory)\n",
        "\n",
        "    for i in my_test_samples_covid_19:\n",
        "        masks.append(mask_directory+i)\n",
        "    images=shuffle(images, random_state=0)\n",
        "    masks=shuffle(masks,random_state=0)\n",
        "    for i in images:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "    for i in masks:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "    image_dataset = []\n",
        "    mask_dataset = []\n",
        "\n",
        "\n",
        "    for i, image_name in enumerate(images):\n",
        "\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        image_dataset.append(image)\n",
        "    for i, image_name in enumerate(masks):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        mask_dataset.append(image)\n",
        "    image_dataset = np.array(image_dataset)/255.\n",
        "    test_image_dataset=np.expand_dims((np.array(image_dataset)),3)\n",
        "    test_mask_dataset = np.expand_dims((np.array(mask_dataset)),3)\n",
        "    image_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_infection_data/Infection_Segmentation_Data/Infection_Segmentation_Data/Val/COVID-19/images/'\n",
        "    mask_directory = '/home/pranab_2021cs25/Segmentation_data/Lung_infection_data/Infection_Segmentation_Data/Infection_Segmentation_Data/Val/COVID-19/infection masks/'\n",
        "    images=[]\n",
        "    my_val_samples_covid_19=os.listdir(image_directory)\n",
        "\n",
        "    for i in my_val_samples_covid_19:\n",
        "        images.append(image_directory+i)\n",
        "\n",
        "    masks=[]\n",
        "    my_val_samples_covid_19=os.listdir(mask_directory)\n",
        "\n",
        "    for i in my_val_samples_covid_19:\n",
        "        masks.append(mask_directory+i)\n",
        "    images=shuffle(images, random_state=0)\n",
        "    masks=shuffle(masks,random_state=0)\n",
        "    for i in images:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "    for i in masks:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "    image_dataset = []\n",
        "    mask_dataset = []\n",
        "    for i, image_name in enumerate(images):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        image_dataset.append(image)\n",
        "    for i, image_name in enumerate(masks):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        mask_dataset.append(image)\n",
        "    image_dataset = np.array(image_dataset)/255.\n",
        "    val_image_dataset=np.expand_dims((np.array(image_dataset)),3)\n",
        "    val_mask_dataset = np.expand_dims((np.array(mask_dataset)),3)\n",
        "    model = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "    pred=model.predict(test_image_dataset)\n",
        "    pred[pred<0.5]=0\n",
        "    pred[pred>=0.5]=1\n",
        "    my_thresholded=pred>0.5\n",
        "    iou_value = compute_iou(test_mask_dataset, my_threshold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBl-yJmDwBfI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "x = dice_metric(test_mask_dataset, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOuBEnu7wBfI",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model1 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "model2 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "model3 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS2yTRrFwBfJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "ans=[]\n",
        "true=[]\n",
        "\n",
        "from tqdm import tqdm\n",
        "for index in tqdm(range(len(test_image_dataset[:20]))):\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model1.predict(test_img_input))\n",
        "    predicted_img1=prediction\n",
        "    predicted_img1[0][predicted_img1[0]<0.5] = 0\n",
        "    predicted_img1[0][predicted_img1[0]>=0.5] = 1\n",
        "\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model2.predict(test_img_input))\n",
        "    predicted_img2=prediction\n",
        "    predicted_img2[0][predicted_img2[0]<0.5] = 0\n",
        "    predicted_img2[0][predicted_img2[0]>=0.5] = 1\n",
        "\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model3.predict(test_img_input))\n",
        "    predicted_img3=prediction\n",
        "    predicted_img3[0][predicted_img3[0]<0.5] = 0\n",
        "    predicted_img3[0][predicted_img3[0]>=0.5] = 1\n",
        "\n",
        "    ground_truth=test_mask_dataset[index]\n",
        "    ground_truth[ground_truth==255] = 1\n",
        "    true.append(ground_truth)\n",
        "    new = np.zeros((256,256))\n",
        "    for i in range(256):\n",
        "        for j in range(256):\n",
        "            if ground_truth[i][j]==predicted_img2[0][i][j]:\n",
        "                new[i][j]=predicted_img2[0][i][j]\n",
        "            elif ground_truth[i][j]==predicted_img1[0][i][j]:\n",
        "                new[i][j]=predicted_img1[0][i][j]\n",
        "            elif ground_truth[i][j]==predicted_img3[0][i][j]:\n",
        "                new[i][j]=predicted_img3[0][i][j]\n",
        "    ans.append(new)\n",
        "\n",
        "true=np.array(true)\n",
        "ans=np.array(ans)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ms9-kTNwBfJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "true=np.squeeze(true,axis=-1)\n",
        "true.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAt_GxZKwBfJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "my_threshold=ans>0.5\n",
        "iou_value = compute_iou(true, my_threshold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VVT7TGRwBfK"
      },
      "outputs": [],
      "source": [
        "x = dice_metric(true, ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R09n12bBwBfK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from datetime import datetime\n",
        "from keras_unet_collection import models, losses\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from PIL import Image\n",
        "import os\n",
        "from PIL import Image\n",
        "import pickle\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import os\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import pickle\n",
        "import warnings\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "import numpy as np\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Activation, add, multiply, UpSampling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    gpu=int(input(\"Which gpu u want?\"))\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu)\n",
        "    image_directory = ''\n",
        "    images=[]\n",
        "    my_train_samples_covid_19=os.listdir(image_directory)\n",
        "\n",
        "    for i in my_train_samples_covid_19:\n",
        "        images.append(image_directory+i)\n",
        "\n",
        "    images=shuffle(images, random_state=0)\n",
        "\n",
        "    for i in images:\n",
        "        x=cv2.imread(i)\n",
        "        i=np.array(x)\n",
        "\n",
        "    image_dataset = []\n",
        "\n",
        "    for i, image_name in enumerate(images):\n",
        "        img = Image.open(image_name).convert('L')\n",
        "        image=np.array(img)\n",
        "        image_dataset.append(image)\n",
        "\n",
        "    image_dataset = np.array(image_dataset)/255.\n",
        "    covid_image_dataset=np.expand_dims((np.array(image_dataset)),-1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4FeQFLZwBfK"
      },
      "outputs": [],
      "source": [
        "import os,glob\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "gpu=int(input(\"Which gpu number you would like to allocate:\"))\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu)\n",
        "model_name=int(input(\"Which model you would like to train(TYPE THE NUMBER ONLY LIKE 1,2,3)? 1. Densenet 201    2. SE Inception v3   3. SE RESNEXT 101\"))\n",
        "import glob\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import re\n",
        "import datetime\n",
        "import keras\n",
        "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import concatenate,Flatten,Layer,ReLU, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.svm import LinearSVC\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog,local_binary_pattern\n",
        "from skimage import data, exposure\n",
        "from skimage.transform import radon, rescale\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "from classification_models.keras import Classifiers\n",
        "from skimage import feature\n",
        "import os,glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import argparse\n",
        "import re\n",
        "import datetime\n",
        "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import concatenate,Flatten,ConvLSTM2D,LayerNormalization,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Sequential\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.svm import LinearSVC\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog,local_binary_pattern\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "from skimage import data, exposure\n",
        "from tensorflow.keras.layers import Layer\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def no_data_augmentation(normal_files,covid_files,pneumonia_files):\n",
        "    aug_normal=[]\n",
        "    aug_covid=[]\n",
        "    aug_pneumonia=[]\n",
        "    for ele in normal_files:\n",
        "        x = Image.open(ele).convert('L')\n",
        "        x = asarray(x)\n",
        "\n",
        "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "        pic=pic/255.0\n",
        "        aug_normal.append(pic)\n",
        "    for ele in covid_files:\n",
        "        x = Image.open(ele).convert('L')\n",
        "        x = asarray(x)\n",
        "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "        pic=pic/255.0\n",
        "        aug_covid.append(pic)\n",
        "    for ele in pneumonia_files:\n",
        "        x = Image.open(ele).convert('L')\n",
        "        x = asarray(x)\n",
        "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "        pic=pic/255.0\n",
        "        aug_pneumonia.append(pic)\n",
        "    for i in range(len(aug_normal)):\n",
        "        aug_normal[i]=aug_normal[i].reshape((224,224))\n",
        "\n",
        "    for i in range(len(aug_covid)):\n",
        "        aug_covid[i]=aug_covid[i].reshape((224,224))\n",
        "    for i in range(len(aug_pneumonia)):\n",
        "        aug_pneumonia[i]=aug_pneumonia[i].reshape((224,224))\n",
        "\n",
        "    return aug_normal,aug_covid,aug_pneumonia\n",
        "\n",
        "def data_augmentation(normal_files,covid_files,pneumonia_files):\n",
        "    aug_normal=[]\n",
        "    aug_covid=[]\n",
        "    thresh_hold=7\n",
        "    aug_pneumonia=[]\n",
        "\n",
        "    datagen=ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "\n",
        "    )\n",
        "    counter=0\n",
        "\n",
        "    for location in tqdm(normal_files):\n",
        "        counter=0\n",
        "\n",
        "        x = Image.open(location).convert('L')\n",
        "        x = asarray(x)\n",
        "\n",
        "        x=cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "        x=x/255.0\n",
        "        x = np.expand_dims(x, axis=-1)\n",
        "        x=x.reshape((1,)+x.shape)\n",
        "        for i in datagen.flow(x):\n",
        "            if counter>=17:\n",
        "                break\n",
        "            aug_normal.append(i)\n",
        "            counter+=1\n",
        "    #covid\n",
        "    counter=0\n",
        "    for location in tqdm(covid_files):\n",
        "        counter=0\n",
        "        x = Image.open(location).convert('L')\n",
        "        x = asarray(x)\n",
        "\n",
        "        x=cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "        x=x/255.0\n",
        "        x = np.expand_dims(x, axis=-1)\n",
        "        x=x.reshape((1,)+x.shape)\n",
        "        for i in datagen.flow(x):\n",
        "            if counter>=2:\n",
        "                break\n",
        "\n",
        "            aug_covid.append(i)\n",
        "            counter+=1\n",
        "    #pneumonia\n",
        "    counter=0\n",
        "    for location in tqdm(pneumonia_files):\n",
        "        counter=0\n",
        "        x = Image.open(location).convert('L')\n",
        "        x = asarray(x)\n",
        "\n",
        "\n",
        "        x=cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "        x=x/255.0\n",
        "        x = np.expand_dims(x, axis=-1)\n",
        "        x=x.reshape((1,)+x.shape)\n",
        "\n",
        "        for i in datagen.flow(x):\n",
        "            if counter>=3:\n",
        "                break\n",
        "            aug_pneumonia.append(i)\n",
        "            counter+=1\n",
        "\n",
        "    for ele in normal_files:\n",
        "        x = Image.open(ele).convert('L')\n",
        "        x = asarray(x)\n",
        "\n",
        "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "        pic=pic/255.0\n",
        "        aug_normal.append(pic)\n",
        "    for ele in covid_files:\n",
        "        x = Image.open(ele).convert('L')\n",
        "        x = asarray(x)\n",
        "\n",
        "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "        pic=pic/255.0\n",
        "        aug_covid.append(pic)\n",
        "    for ele in pneumonia_files:\n",
        "        x = Image.open(ele).convert('L')\n",
        "        x = asarray(x)\n",
        "\n",
        "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "        pic=pic/255.0\n",
        "        aug_pneumonia.append(pic)\n",
        "    for i in range(len(aug_normal)):\n",
        "        aug_normal[i]=aug_normal[i].reshape((224,224))\n",
        "\n",
        "    for i in range(len(aug_covid)):\n",
        "        aug_covid[i]=aug_covid[i].reshape((224,224))\n",
        "    for i in range(len(aug_pneumonia)):\n",
        "        aug_pneumonia[i]=aug_pneumonia[i].reshape((224,224))\n",
        "\n",
        "    return aug_normal,aug_covid,aug_pneumonia\n",
        "\n",
        "def making_full_data(aug_normal,aug_covid,aug_pneumonia):\n",
        "    aug_normal=shuffle(aug_normal, random_state=0)\n",
        "    aug_covid=shuffle(aug_covid,random_state=0)\n",
        "    aug_pneumonia=shuffle(aug_pneumonia,random_state=0)\n",
        "\n",
        "    aug_normal_labels=[]\n",
        "    for i in range(len(aug_normal)):\n",
        "        aug_normal_labels.append(0)\n",
        "    aug_covid_labels=[]\n",
        "    for i in range(len(aug_covid)):\n",
        "        aug_covid_labels.append(1)\n",
        "    aug_pneumonia_labels=[]\n",
        "    for i in range(len(aug_pneumonia)):\n",
        "        aug_pneumonia_labels.append(2)\n",
        "\n",
        "    full_data=[]\n",
        "    full_label=[]\n",
        "    for i in range(len(aug_normal)):\n",
        "        full_data.append(aug_normal[i])\n",
        "        full_label.append(aug_normal_labels[i])\n",
        "    for i in range(len(aug_covid)):\n",
        "        full_data.append(aug_covid[i])\n",
        "        full_label.append(aug_covid_labels[i])\n",
        "    for i in range(len(aug_pneumonia)):\n",
        "        full_data.append(aug_pneumonia[i])\n",
        "        full_label.append(aug_pneumonia_labels[i])\n",
        "\n",
        "    full_data=np.array(full_data)\n",
        "    full_label=np.array(full_label)\n",
        "\n",
        "    full_data=shuffle(full_data,random_state=0)\n",
        "    full_label=shuffle(full_label,random_state=0)\n",
        "\n",
        "    return full_data,full_label\n",
        "\"\"\"Inception 2D_CNN Models in Tensorflow-Keras.\n",
        "References -\n",
        "Inception_v1 (GoogLeNet): https://arxiv.org/abs/1409.4842 [Going Deeper with Convolutions]\n",
        "Inception_v2: http://arxiv.org/abs/1512.00567 [Rethinking the Inception Architecture for Computer Vision]\n",
        "Inception_v3: http://arxiv.org/abs/1512.00567 [Rethinking the Inception Architecture for Computer Vision]\n",
        "Inception_v4: https://arxiv.org/abs/1602.07261 [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def making_training_and_testing_data(full_data,full_label):\n",
        "\n",
        "\n",
        "    train_label=[]\n",
        "    for i in range(len(full_label)):\n",
        "        if full_label[i]==0:\n",
        "            train_label.append([0,1,0])\n",
        "        elif full_label[i]==1:\n",
        "            train_label.append([1,0,0])\n",
        "        elif full_label[i]==2:\n",
        "\n",
        "            train_label.append([0,0,1])\n",
        "\n",
        "\n",
        "    full_label=np.array(train_label)\n",
        "\n",
        "\n",
        "    return full_data,full_label\n",
        "\n",
        "def my_plots(history,my_model):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    my_path=\"training and validation accuracy curve of \"+my_model+\".png\"\n",
        "    plt.savefig(my_path)\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylim([0, 1])\n",
        "\n",
        "    #plt.ylim([-3, 3])\n",
        "    plt.yticks(np.arange(0, 1.1, 0.25))\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "    my_path=\"training and validation loss curve of \"+my_model+\".png\"\n",
        "    plt.savefig(my_path)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':  #straight away go to this\n",
        "\n",
        "    normal_dir = \"\"  #give your covid 19 cases data path here\n",
        "    dir1 = os.path.join(normal_dir,\"*.png\")\n",
        "    dir = os.path.join(normal_dir,\"*.jpg\")\n",
        "    dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
        "    covid_files = glob.glob(dir)\n",
        "    covid_files2 = glob.glob(dir2)\n",
        "    covid_files1 = glob.glob(dir1)\n",
        "    covid_files.extend(covid_files2)\n",
        "    covid_files.extend(covid_files1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b6sF6IfwBfL"
      },
      "outputs": [],
      "source": [
        "from numpy import asarray\n",
        "image_directory = ''\n",
        "images=[]\n",
        "my_test_samples_covid_19=os.listdir(image_directory)\n",
        "\n",
        "for i in my_test_samples_covid_19:\n",
        "    images.append(image_directory+i)\n",
        "images=shuffle(images, random_state=0)\n",
        "\n",
        "for i in images:\n",
        "    x=cv2.imread(i)\n",
        "    i=np.array(x)\n",
        "    if i.shape!=(256,256,3):\n",
        "        break\n",
        "\n",
        "image_dataset = []\n",
        "for i, image_name in enumerate(images):\n",
        "    img = Image.open(image_name).convert('L')\n",
        "    x = asarray(img)\n",
        "    image = cv2.resize(x,(256,256))\n",
        "    image_dataset.append(image)\n",
        "\n",
        "for i in range(len(image_dataset)):\n",
        "    image_dataset[i]=image_dataset[i].reshape((256,256))\n",
        "\n",
        "image_dataset = np.array(image_dataset)/255.\n",
        "test_image_dataset=np.expand_dims((np.array(image_dataset)),3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MvRyJ_7wBfL"
      },
      "outputs": [],
      "source": [
        "model = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "model1 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "model2 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "model3 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "#give models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awvDSFSswBfM"
      },
      "outputs": [],
      "source": [
        "x=model4.predict(test_image_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlJHKOK9wBfM"
      },
      "outputs": [],
      "source": [
        "ans=[]\n",
        "true=[]\n",
        "from tqdm import tqdm\n",
        "for index in tqdm(range(len(test_image_dataset[:700]))):\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model1.predict(test_img_input))\n",
        "    predicted_img1=prediction\n",
        "    predicted_img1[0][predicted_img1[0]<0.5] = 0\n",
        "    predicted_img1[0][predicted_img1[0]>=0.5] = 1\n",
        "\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model2.predict(test_img_input))\n",
        "    predicted_img2=prediction\n",
        "    predicted_img2[0][predicted_img2[0]<0.5] = 0\n",
        "    predicted_img2[0][predicted_img2[0]>=0.5] = 1\n",
        "\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model3.predict(test_img_input))\n",
        "    predicted_img3=prediction\n",
        "    predicted_img3[0][predicted_img3[0]<0.5] = 0\n",
        "    predicted_img3[0][predicted_img3[0]>=0.5] = 1\n",
        "\n",
        "    new = np.zeros((256,256))\n",
        "    for i in range(256):\n",
        "        for j in range(256):\n",
        "            count_1=0\n",
        "            count_0=0\n",
        "            if predicted_img1[0][i][j]==1:\n",
        "                count_1+=1\n",
        "            else:\n",
        "                count_0+=1\n",
        "            if predicted_img2[0][i][j]==1:\n",
        "                count_1+=1\n",
        "            else:\n",
        "                count_0+=1\n",
        "            if predicted_img3[0][i][j]==1:\n",
        "                count_1+=1\n",
        "            else:\n",
        "                count_0+=1\n",
        "\n",
        "            if count_1>=count_0:\n",
        "                new[i][j]=1\n",
        "            else:\n",
        "                new[i][j]=0\n",
        "\n",
        "    ans.append(new)\n",
        "\n",
        "true=np.array(true)\n",
        "ans=np.array(ans)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQgl_fMWwBfM"
      },
      "outputs": [],
      "source": [
        "model1 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "model2 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})\n",
        "model3 = load_model('',custom_objects={'dice_coef_loss':dice_coef_loss,'dice_coef':dice_coef,'iou_score':iou_score})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MidV9JifwBfM"
      },
      "outputs": [],
      "source": [
        "infection=[]\n",
        "true=[]\n",
        "\n",
        "from tqdm import tqdm\n",
        "for index in tqdm(range(len(test_image_dataset[:700]))):\n",
        "\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model1.predict(test_img_input))\n",
        "    predicted_img1=prediction\n",
        "    predicted_img1[0][predicted_img1[0]<0.5] = 0\n",
        "    predicted_img1[0][predicted_img1[0]>=0.5] = 1\n",
        "\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model2.predict(test_img_input))\n",
        "    predicted_img2=prediction\n",
        "    predicted_img2[0][predicted_img2[0]<0.5] = 0\n",
        "    predicted_img2[0][predicted_img2[0]>=0.5] = 1\n",
        "\n",
        "    test_img = test_image_dataset[index]\n",
        "    test_img_input=np.expand_dims(test_img, 0)\n",
        "    prediction = (model3.predict(test_img_input))\n",
        "    predicted_img3=prediction\n",
        "    predicted_img3[0][predicted_img3[0]<0.5] = 0\n",
        "    predicted_img3[0][predicted_img3[0]>=0.5] = 1\n",
        "\n",
        "    new = np.zeros((256,256))\n",
        "\n",
        "    for i in range(256):\n",
        "        for j in range(256):\n",
        "            count_1=0\n",
        "            count_0=0\n",
        "            if predicted_img1[0][i][j]==1:\n",
        "                count_1+=1\n",
        "            else:\n",
        "                count_0+=1\n",
        "            if predicted_img2[0][i][j]==1:\n",
        "                count_1+=1\n",
        "            else:\n",
        "                count_0+=1\n",
        "            if predicted_img3[0][i][j]==1:\n",
        "                count_1+=1\n",
        "            else:\n",
        "                count_0+=1\n",
        "\n",
        "            if count_1>=count_0:\n",
        "                new[i][j]=1\n",
        "            else:\n",
        "                new[i][j]=0\n",
        "\n",
        "    infection.append(new)\n",
        "\n",
        "true=np.array(true)\n",
        "infection=np.array(infection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmSv8-Y6wBfN"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "for k in tqdm(range(len(ans))):\n",
        "    lung=ans[k]\n",
        "    inf=infection[k]\n",
        "    counter_lung=0\n",
        "    counter_inf=0\n",
        "    for i in range(256):\n",
        "        for j in range(256):\n",
        "            if lung[i][j]==1:\n",
        "                counter_lung+=1\n",
        "            if inf[i][j]==1:\n",
        "                counter_inf+=1\n",
        "    div=(counter_inf/counter_lung)\n",
        "    div=div*100\n",
        "    if div>35 and div<50:\n",
        "        print(k)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tRHfGO_wBfN"
      },
      "outputs": [],
      "source": [
        "lung=ans[371]\n",
        "inf=infection[371]\n",
        "counter_lung=0\n",
        "counter_inf=0\n",
        "for i in range(256):\n",
        "    for j in range(256):\n",
        "        if lung[i][j]==1:\n",
        "            counter_lung+=1\n",
        "        if inf[i][j]==1:\n",
        "            counter_inf+=1\n",
        "div=(counter_inf/counter_lung)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dy4P7ZXwBfN"
      },
      "outputs": [],
      "source": [
        "xx=np.expand_dims(infection[371],axis=-1)\n",
        "ret,thresh=cv2.threshold(xx,127,255,0)\n",
        "x=np.stack((ans[371],)*3,axis=-1)\n",
        "image_filename = \"ans_image.jpeg\"\n",
        "import matplotlib.image\n",
        "matplotlib.image.imsave(image_filename, x)\n",
        "img=cv2.imread(\"ans_image.jpeg\")\n",
        "img_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "_,thresh=cv2.threshold(img_gray,127,255,cv2.THRESH_BINARY)\n",
        "contours,hierarchy=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
        "contours = sorted(contours, key = cv2.contourArea)[-2:]\n",
        "img=cv2.imread(images[371])\n",
        "img = cv2.resize(img,(256,256))\n",
        "image_filename = \"test_image.jpeg\"\n",
        "matplotlib.image.imsave(image_filename, img)\n",
        "x=np.stack((infection[371],)*3,axis=-1)\n",
        "image_filename = \"infection_image.jpeg\"\n",
        "matplotlib.image.imsave(image_filename, x)\n",
        "img2=cv2.imread(\"infection_image.jpeg\")\n",
        "img_gray=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
        "_,thresh=cv2.threshold(img_gray,127,255,cv2.THRESH_BINARY)\n",
        "contours,hierarchy=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
        "contours = sorted(contours, key = cv2.contourArea)[-2:]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
