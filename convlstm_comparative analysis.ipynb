{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMHEzfyf9Emt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsUlpB8U6leV"
      },
      "outputs": [],
      "source": [
        "import os,glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import re\n",
        "import datetime\n",
        "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import concatenate,Flatten,Layer,ReLU, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.svm import LinearSVC\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog,local_binary_pattern\n",
        "from skimage import data, exposure\n",
        "from skimage.transform import radon, rescale\n",
        "from skimage.filters import roberts, sobel, scharr, prewitt\n",
        "from skimage import feature\n",
        "import os,glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import re\n",
        "import datetime\n",
        "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\n",
        "from tensorflow.keras.layers import concatenate,Flatten,ConvLSTM2D,LayerNormalization,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Sequential\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.svm import LinearSVC\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage.feature import hog,local_binary_pattern\n",
        "from skimage import data, exposure\n",
        "from tensorflow.keras.layers import Layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAX6c2NP6leW"
      },
      "outputs": [],
      "source": [
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtu_jitf6leW"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eReSFeMI6leW"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJukIjJZ6leX"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d tawsifurrahman/covid19-radiography-database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT_B2rO66leX"
      },
      "outputs": [],
      "source": [
        "!unzip /content/covid19-radiography-database.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcopUbP36leX"
      },
      "outputs": [],
      "source": [
        "normal_dir = \"\" #add ur own path\n",
        "dir1 = os.path.join(normal_dir,\"*.png\")\n",
        "dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
        "dir = os.path.join(normal_dir,\"*.jpg\")\n",
        "normal_files = glob.glob(dir)\n",
        "normal_1 = glob.glob(dir1)\n",
        "normal_2 = glob.glob(dir2)\n",
        "normal_files.extend(normal_1)\n",
        "normal_files.extend(normal_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3JJ6xyR6leX"
      },
      "outputs": [],
      "source": [
        "normal_dir = \"\" #add ur own path\n",
        "dir1 = os.path.join(normal_dir,\"*.png\")\n",
        "dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
        "dir = os.path.join(normal_dir,\"*.jpg\")\n",
        "pneumonia_files = glob.glob(dir)\n",
        "pneumonia_1 = glob.glob(dir1)\n",
        "pneumonia_2 = glob.glob(dir2)\n",
        "pneumonia_files.extend(pneumonia_1)\n",
        "pneumonia_files.extend(pneumonia_2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O34YdvPq6leY"
      },
      "outputs": [],
      "source": [
        "normal_dir = \"\" #add ur own path\n",
        "dir1 = os.path.join(normal_dir,\"*.png\")\n",
        "dir = os.path.join(normal_dir,\"*.jpg\")\n",
        "dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
        "covid_files = glob.glob(dir)\n",
        "covid_files2 = glob.glob(dir2)\n",
        "covid_files1 = glob.glob(dir1)\n",
        "covid_files.extend(covid_files2)\n",
        "covid_files.extend(covid_files1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwEnH4wKYGa8"
      },
      "outputs": [],
      "source": [
        "normal_files.sort()\n",
        "covid_files.sort()\n",
        "pneumonia_files.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmiYHLHA6leY"
      },
      "outputs": [],
      "source": [
        "train_dic = {}\n",
        "for f in covid_files[:2604]:\n",
        "  train_dic[f] = [1,0,0]\n",
        "for f in normal_files[:7339]:\n",
        "  train_dic[f] = [0,1,0]\n",
        "for f in pneumonia_files[:968]:\n",
        "  train_dic[f] = [0,0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kFyJji--nfK"
      },
      "outputs": [],
      "source": [
        "val_dic = {}\n",
        "for f in covid_files[2604:2893]:\n",
        "  val_dic[f] = [1,0,0]\n",
        "for f in normal_files[7339:8154]:\n",
        "  val_dic[f] = [0,1,0]\n",
        "for f in pneumonia_files[968:1076]:\n",
        "  val_dic[f] = [0,0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm5H2gHI__GD"
      },
      "outputs": [],
      "source": [
        "\n",
        "import random\n",
        "l_val = list(val_dic.items())\n",
        "random.Random(4).shuffle(l_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bS9hfXv6leY"
      },
      "outputs": [],
      "source": [
        "test_dic = {}\n",
        "for f in covid_files[2893:]:\n",
        "  test_dic[f] = [1,0,0]\n",
        "for f in normal_files[8154:]:\n",
        "  test_dic[f] = [0,1,0]\n",
        "for f in pneumonia_files[1076:]:\n",
        "  test_dic[f] = [0,0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSgDyI7H6leZ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "l = list(train_dic.items())\n",
        "random.Random(4).shuffle(l)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H09VINRp6leZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import random\n",
        "l_test = list(test_dic.items())\n",
        "random.Random(4).shuffle(l_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaNL-lttpKFi"
      },
      "outputs": [],
      "source": [
        "len(l_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1DzmVwE6leZ"
      },
      "outputs": [],
      "source": [
        "print(len(l),len(l_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6twNO79pfFgs"
      },
      "outputs": [],
      "source": [
        "val_features = []\n",
        "covid_dic_list = {}\n",
        "data = []\n",
        "labels = []\n",
        "for i in range(len(l_val)):\n",
        "  file_name,label = l_val[i]\n",
        "  img = cv2.imread(file_name)\n",
        "\n",
        "  img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "  height, width = img.shape[:2]\n",
        "  img = img.astype('float32')/255.0\n",
        "  data.append(img)\n",
        "  labels.append(label)\n",
        "\n",
        "\n",
        "val_data = np.array(data)\n",
        "print(val_data.shape)\n",
        "val_labels = np.array(labels)\n",
        "print(val_labels.shape)    \n",
        "print('^_^-training data finished-^_^')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKcrGRhYHQZH"
      },
      "outputs": [],
      "source": [
        "train_features = []\n",
        "covid_dic_list = {}\n",
        "data = []\n",
        "labels = []\n",
        "for i in range(len(l)):\n",
        "  file_name,label = l[i]\n",
        "  img = cv2.imread(file_name)\n",
        "  try:\n",
        "    img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "    height, width = img.shape[:2]\n",
        "    img = img.astype('float32')/255.0\n",
        "    data.append(img)\n",
        "    train_features.append((img[:,:,2]))\n",
        "    labels.append(label)\n",
        "\n",
        "  except:\n",
        "    print(i,file_name)\n",
        "    print(\"Not possible\")  \n",
        "train_data = np.array(data)\n",
        "print(train_data.shape)\n",
        "train_labels = np.array(labels)\n",
        "print(train_labels.shape)    \n",
        "print('^_^-training data finished-^_^')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZWANIICQ6rz"
      },
      "outputs": [],
      "source": [
        "test_features = []\n",
        "data = []\n",
        "labels = []\n",
        "for i in range(len(l_test)):\n",
        "  file_name,label = l_test[i]\n",
        "  img = cv2.imread(file_name)\n",
        "  try:\n",
        "    img = cv2.resize(img,(224,224),interpolation = cv2.INTER_CUBIC)\n",
        "    img = img.astype('float32')/255.0\n",
        "    data.append(img)\n",
        "    test_features.append((img[:,:,2]))\n",
        "    labels.append(label)\n",
        "  except:\n",
        "    print(file_name,i)  \n",
        " \n",
        "  \n",
        "test_data = np.array(data)\n",
        "print(test_data.shape)\n",
        "test_labels = np.array(labels)\n",
        "print(test_labels.shape)    \n",
        "print('^_^-testing data finished-^_^')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WslhT4f49s28"
      },
      "outputs": [],
      "source": [
        "inception_model = tf.keras.applications.InceptionV3(include_top=False,weights='imagenet',classes = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ORV1j5m9s29"
      },
      "outputs": [],
      "source": [
        "inception_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZS029fQ9s29"
      },
      "outputs": [],
      "source": [
        "\n",
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "x = inception_model(inputs)\n",
        "input_ = tf.expand_dims(x,axis = 1)\n",
        "nb_chan = 512\n",
        "ratio = 16\n",
        "x3 = ConvLSTM2D(filters=512, kernel_size=(1,1),padding = \"same\")(input_) \n",
        "x3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001)(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "\n",
        "\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(x3)\n",
        "y = tf.keras.layers.Dense(nb_chan // ratio, activation='relu')(y)\n",
        "y = tf.keras.layers.Dense(nb_chan, activation='sigmoid')(y)\n",
        "y_3 = tf.keras.layers.Multiply()([x3, y])\n",
        "\n",
        "ratio = 16\n",
        "flat = Flatten()(y_3)\n",
        "\n",
        "dense_1 = Dense(4096,activation = 'relu')(flat)\n",
        "dense_2 = Dense(4096,activation = 'relu')(dense_1)\n",
        "prediction = Dense(3,activation = 'softmax')(dense_2)\n",
        "inception_pred = Model(inputs = inputs,outputs = prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B07sp7qN9s29"
      },
      "outputs": [],
      "source": [
        "# inception_pred.summary()\n",
        "inception_pred.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht7WMX9H9s29"
      },
      "outputs": [],
      "source": [
        "inception_pred.fit(train_data,train_labels,epochs = 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFRdOFX39s29"
      },
      "outputs": [],
      "source": [
        "inception_pred.evaluate(test_data,test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ozC-K_j-X8p"
      },
      "outputs": [],
      "source": [
        "inception_pred.load_weights(\"120radiagraphy-newinception_combined.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPIODkvfOe8e"
      },
      "outputs": [],
      "source": [
        "vgg_model = tf.keras.applications.VGG19(include_top=False,weights='imagenet',classes = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3kX0_3sOe8e"
      },
      "outputs": [],
      "source": [
        "vgg_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD0TM9KpOe8e"
      },
      "outputs": [],
      "source": [
        "\n",
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "#x = inputs\n",
        "x = vgg_model(inputs)\n",
        "input_ = tf.expand_dims(x,axis = 1)\n",
        "nb_chan = 512\n",
        "ratio = 16\n",
        "x3 = ConvLSTM2D(filters=512, kernel_size=(1,1),padding = \"same\")(input_) \n",
        "x3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001)(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "\n",
        "#x_add = Add()([x1,x3])\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(x3)\n",
        "y = tf.keras.layers.Dense(nb_chan // ratio, activation='relu')(y)\n",
        "y = tf.keras.layers.Dense(nb_chan, activation='sigmoid')(y)\n",
        "y_3 = tf.keras.layers.Multiply()([x3, y])\n",
        "\n",
        "ratio = 16\n",
        "flat = Flatten()(y_3)\n",
        "\n",
        "dense_1 = Dense(4096,activation = 'relu')(flat)\n",
        "dense_2 = Dense(4096,activation = 'relu')(dense_1)\n",
        "prediction = Dense(3,activation = 'softmax')(dense_2)\n",
        "vgg_pred = Model(inputs = inputs,outputs = prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thf0D2M4Oe8f"
      },
      "outputs": [],
      "source": [
        "vgg_pred.summary()\n",
        "vgg_pred.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCsRBjQ3Oe8f"
      },
      "outputs": [],
      "source": [
        "vgg_pred.fit(train_data,train_labels,epochs = 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaZeeBCmOe8f"
      },
      "outputs": [],
      "source": [
        "vgg_pred.evaluate(test_data,test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_qENstnOe8f"
      },
      "outputs": [],
      "source": [
        "vgg_pred.load_weights(\"120radiagraphy-newvgg_combined.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbfduXprkXUX"
      },
      "outputs": [],
      "source": [
        "mobile_model = tf.keras.applications.MobileNet(input_shape=(224,224,3),include_top=False,weights='imagenet',classes = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1RGVAUPkXUX"
      },
      "outputs": [],
      "source": [
        "mobile_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdg32MItkXUX"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(224,224,3))\n",
        "\n",
        "x = mobile_model(inputs)\n",
        "input_ = tf.expand_dims(x,axis = 1)\n",
        "nb_chan = 512\n",
        "ratio = 16\n",
        "x3 = ConvLSTM2D(filters=512, kernel_size=(1,1),padding = \"same\")(input_) \n",
        "x3 = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001)(x3)\n",
        "x3 = Activation('relu')(x3)\n",
        "\n",
        "\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(x3)\n",
        "y = tf.keras.layers.Dense(nb_chan // ratio, activation='relu')(y)\n",
        "y = tf.keras.layers.Dense(nb_chan, activation='sigmoid')(y)\n",
        "y_3 = tf.keras.layers.Multiply()([x3, y])\n",
        "\n",
        "ratio = 16\n",
        "flat = Flatten()(y_3)\n",
        "dense_1 = Dense(4096,activation = 'relu')(flat)\n",
        "dense_2 = Dense(4096,activation = 'relu')(dense_1)\n",
        "prediction = Dense(3,activation = 'softmax')(dense_2)\n",
        "mobile_pred = Model(inputs = inputs,outputs = prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTd2JanNkXUX"
      },
      "outputs": [],
      "source": [
        "mobile_pred.summary()\n",
        "mobile_pred.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00002), loss=tf.keras.losses.CategoricalCrossentropy(from_logits = False) , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwUtNKPskXUY"
      },
      "outputs": [],
      "source": [
        "mobile_pred.fit(train_data,train_labels,epochs = 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOfGj-RVkXUY"
      },
      "outputs": [],
      "source": [
        "mobile_pred.evaluate(test_data,test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djM6PjTWkXUY"
      },
      "outputs": [],
      "source": [
        "mobile_pred.load_weights(\"radiagraphy-newmobilenetv1_combined.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2jzkwf8fFx7"
      },
      "outputs": [],
      "source": [
        "test3 = vgg_pred.predict(test_data)\n",
        "test4 = mobile_pred.predict(test_data)\n",
        "test5 = inception_pred.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLKPlgBHfFx8"
      },
      "outputs": [],
      "source": [
        "new_test3 = np.argmax(test3,axis = 1)\n",
        "new_test4 = np.argmax(test4,axis = 1)\n",
        "new_test5 = np.argmax(test5,axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbmwAwdTfFx8"
      },
      "outputs": [],
      "source": [
        "val3 = vgg_pred.predict(val_data)\n",
        "val4 = mobile_pred.predict(val_data)\n",
        "val5 = inception_pred.predict(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vxJT9pKfFx8"
      },
      "outputs": [],
      "source": [
        "new_val3 = np.argmax(val3,axis = 1)\n",
        "new_val4 = np.argmax(val4,axis = 1)\n",
        "new_val5 = np.argmax(val5,axis = 1)\n",
        "val_l = np.argmax(val_labels,axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7VJptxWBCl5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uRLCN28KM34"
      },
      "outputs": [],
      "source": [
        "def sugeno(solution,pred1,pred2,pred3, labels):\n",
        "    fuzzymeasures = np.array([solution[0],solution[1],solution[2]])\n",
        "    l = Symbol('l', real = True)\n",
        "    lam = solve(  ( 1 + l* fuzzymeasures[0]) * ( 1 + l* fuzzymeasures[1]) *( 1 + l* fuzzymeasures[2]) - (l+1), l )\n",
        "    if len(lam) < 3:\n",
        "      lam = np.asarray(lam)\n",
        "    else:\n",
        "      if lam[0] >= 0:\n",
        "          lam = np.asarray(lam[2])\n",
        "      elif lam[1] >= 0:\n",
        "          lam = np.asarray(lam[2])\n",
        "      elif lam[2] >= 0:\n",
        "          lam = np.asarray(lam[2])\n",
        "    \n",
        "    Ypred_fuzzy = np.zeros(shape = pred1.shape, dtype = float)\n",
        "    for sample in range(0,pred1.shape[0]):\n",
        "        for classes in range(0,3):\n",
        "            scores = np.array([pred1[sample][classes],pred2[sample][classes],pred3[sample][classes]])\n",
        "            permutedidx = np.flip(np.argsort(scores))\n",
        "            scoreslambda = scores[permutedidx]\n",
        "            fmlambda = fuzzymeasures[permutedidx]\n",
        "            ge_prev = fmlambda[0]\n",
        "            fuzzyprediction = min((scoreslambda[0], fmlambda[0]))\n",
        "            for i in range(1,3):\n",
        "                ge_curr = ge_prev + fmlambda[i] + lam * fmlambda[i] * ge_prev\n",
        "                fuzzyprediction = max((fuzzyprediction,min((scoreslambda[i],ge_curr))))\n",
        "                ge_prev = ge_curr\n",
        "\n",
        "            Ypred_fuzzy[sample][classes] = fuzzyprediction\n",
        "    ypred_fuzzy = np.argmax(Ypred_fuzzy, axis=1)\n",
        "    pred_label = []\n",
        "    for i in ypred_fuzzy:\n",
        "      label = np.zeros((3))\n",
        "      label[i] = label[i]+1\n",
        "      pred_label.append(label)\n",
        "    pred_label = np.array(pred_label)\n",
        "    acc = accuracy_score(labels,pred_label)\n",
        "    #print(acc)\n",
        "    return -acc, ypred_fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1bkv9NIfFx8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sympy.solvers import solve\n",
        "from sympy import Symbol\n",
        "import numpy as np\n",
        "# The fuzzy measure values selected by experimentally tuning on the validation set is [0.96505245,1.29024978,0.6804187]\n",
        "acc,ypred = sugeno([0.96505245,1.29024978,0.6804187],test3,test4,test5,test_labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Covid19-Radiography",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
