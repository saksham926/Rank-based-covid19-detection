{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025bb857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "gpu=int(input(\"Which gpu number you would like to allocate:\"))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu)\n",
    "model_name=int(input(\"Which model you would like to train(TYPE THE NUMBER ONLY LIKE 1,2,3)? 1. SE Inception v3    2. DENSENET 201   3. SE SQUEEZENET\"))\n",
    "import glob\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import re\n",
    "import datetime\n",
    "import keras\n",
    "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\n",
    "from tensorflow.keras.layers import concatenate,Flatten,Layer,ReLU, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage.feature import hog,local_binary_pattern\n",
    "from skimage import data, exposure\n",
    "from skimage.transform import radon, rescale\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "from classification_models.keras import Classifiers\n",
    "from skimage import feature\n",
    "import os,glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import argparse\n",
    "import re\n",
    "import datetime\n",
    "from tensorflow.keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract,LeakyReLU,Add,Average,Lambda,MaxPool2D,Dropout,UpSampling2D,Concatenate,Multiply,GlobalAveragePooling2D,Dense,ZeroPadding2D,AveragePooling2D\n",
    "from tensorflow.keras.layers import concatenate,Flatten,ConvLSTM2D,LayerNormalization,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Sequential\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage.feature import hog,local_binary_pattern\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from skimage import data, exposure\n",
    "from tensorflow.keras.layers import Layer\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def no_data_augmentation(normal_files,covid_files,pneumonia_files):\n",
    "    aug_normal=[]\n",
    "    aug_covid=[]\n",
    "    aug_pneumonia=[]\n",
    "    for ele in normal_files:\n",
    "        #ele=ele/255.0\n",
    "        x = Image.open(ele).convert('L')\n",
    "        x = asarray(x)\n",
    "        \n",
    "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "        pic=pic/255.0\n",
    "        aug_normal.append(pic)\n",
    "    for ele in covid_files:\n",
    "        #ele=ele/255.0\n",
    "        x = Image.open(ele).convert('L')\n",
    "        x = asarray(x)\n",
    "        \n",
    "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "        pic=pic/255.0\n",
    "        aug_covid.append(pic)\n",
    "    for ele in pneumonia_files:\n",
    "        #ele=ele/255.0\n",
    "        x = Image.open(ele).convert('L')\n",
    "        x = asarray(x)\n",
    "      \n",
    "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "        pic=pic/255.0\n",
    "        aug_pneumonia.append(pic)\n",
    "    for i in range(len(aug_normal)):\n",
    "        aug_normal[i]=aug_normal[i].reshape((224,224))\n",
    "    \n",
    "    for i in range(len(aug_covid)):\n",
    "        aug_covid[i]=aug_covid[i].reshape((224,224))\n",
    "    for i in range(len(aug_pneumonia)):\n",
    "        aug_pneumonia[i]=aug_pneumonia[i].reshape((224,224))\n",
    "    \n",
    "    print(\"Normal files without augmentation:\",len(aug_normal))\n",
    "    print(\"Covid files without augmentation:\", len(aug_covid))\n",
    "    print(\"Pneumonia files without augmentation:\",len(aug_pneumonia))\n",
    "    return aug_normal,aug_covid,aug_pneumonia\n",
    "\n",
    "def data_augmentation(normal_files,covid_files,pneumonia_files):\n",
    "    aug_normal=[]\n",
    "    aug_covid=[]\n",
    "    thresh_hold=7\n",
    "    aug_pneumonia=[]\n",
    "    \n",
    "    #x = tf.keras.preprocessing.image.load_img(\"/content/IM-0001-0001.jpeg\")\n",
    "    \n",
    "    datagen=ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "\n",
    "    )\n",
    "    #normal\n",
    "    counter=0\n",
    "    \n",
    "    for location in tqdm(normal_files):\n",
    "        counter=0\n",
    "\n",
    "        x = Image.open(location).convert('L')\n",
    "        x = asarray(x)\n",
    "       \n",
    "        x=cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "        x=x/255.0\n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        x=x.reshape((1,)+x.shape)\n",
    "        #x=x/255.0\n",
    "\n",
    "\n",
    "        for i in datagen.flow(x):\n",
    "            if counter>=12:\n",
    "                break\n",
    "            #i=i/255.0\n",
    "\n",
    "            #i = cv2.resize(i,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "            aug_normal.append(i)\n",
    "            counter+=1\n",
    "    #covid\n",
    "    counter=0\n",
    "    for location in tqdm(covid_files):\n",
    "        counter=0\n",
    "        x = Image.open(location).convert('L')\n",
    "        x = asarray(x)\n",
    "    \n",
    "        x=cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "        x=x/255.0\n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        #x=img_to_array(x)\n",
    "        x=x.reshape((1,)+x.shape)\n",
    "        #x=x/255.0\n",
    "\n",
    "\n",
    "        for i in datagen.flow(x):\n",
    "            if counter>=2:\n",
    "                break\n",
    "\n",
    "            aug_covid.append(i)\n",
    "            counter+=1    \n",
    "    #pneumonia\n",
    "    counter=0\n",
    "    for location in tqdm(pneumonia_files):\n",
    "        counter=0\n",
    "        x = Image.open(location).convert('L')\n",
    "        x = asarray(x)\n",
    "    \n",
    "\n",
    "        x=cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "        x=x/255.0\n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        #x=img_to_array(x)\n",
    "        x=x.reshape((1,)+x.shape)\n",
    "        #x=x/255.0\n",
    "\n",
    "        for i in datagen.flow(x):\n",
    "            if counter>=3:\n",
    "                break\n",
    "            #i=i/255.0\n",
    "            #i = cv2.resize(i,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "            aug_pneumonia.append(i)\n",
    "            counter+=1    \n",
    "\n",
    "    for ele in normal_files:\n",
    "        #ele=ele/255.0\n",
    "        x = Image.open(ele).convert('L')\n",
    "        x = asarray(x)\n",
    "        \n",
    "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "        pic=pic/255.0\n",
    "        aug_normal.append(pic)\n",
    "    for ele in covid_files:\n",
    "        #ele=ele/255.0\n",
    "        x = Image.open(ele).convert('L')\n",
    "        x = asarray(x)\n",
    "        \n",
    "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "        pic=pic/255.0\n",
    "        aug_covid.append(pic)\n",
    "    for ele in pneumonia_files:\n",
    "        #ele=ele/255.0\n",
    "        x = Image.open(ele).convert('L')\n",
    "        x = asarray(x)\n",
    "      \n",
    "        pic = cv2.resize(x,(224,224),interpolation = cv2.INTER_CUBIC)\n",
    "        pic=pic/255.0\n",
    "        aug_pneumonia.append(pic)\n",
    "    for i in range(len(aug_normal)):\n",
    "        aug_normal[i]=aug_normal[i].reshape((224,224))\n",
    "    \n",
    "    for i in range(len(aug_covid)):\n",
    "        aug_covid[i]=aug_covid[i].reshape((224,224))\n",
    "    for i in range(len(aug_pneumonia)):\n",
    "        aug_pneumonia[i]=aug_pneumonia[i].reshape((224,224))\n",
    "    \n",
    "    print(\"Normal files after augmentation:\",len(aug_normal))\n",
    "    print(\"Covid files after augmentation:\", len(aug_covid))\n",
    "    print(\"Pneumonia files after augmentation:\",len(aug_pneumonia))\n",
    "    return aug_normal,aug_covid,aug_pneumonia\n",
    "\n",
    "def making_full_data(aug_normal,aug_covid,aug_pneumonia):\n",
    "    aug_normal=shuffle(aug_normal, random_state=0)\n",
    "    aug_covid=shuffle(aug_covid,random_state=0)\n",
    "    aug_pneumonia=shuffle(aug_pneumonia,random_state=0)\n",
    "    \n",
    "    aug_normal_labels=[]\n",
    "    for i in range(len(aug_normal)):\n",
    "        aug_normal_labels.append(0)\n",
    "    print(np.shape(aug_normal),np.shape(aug_normal_labels))\n",
    "    aug_covid_labels=[]\n",
    "    for i in range(len(aug_covid)):\n",
    "        aug_covid_labels.append(1)\n",
    "    print(np.shape(aug_covid),np.shape(aug_covid_labels))\n",
    "    aug_pneumonia_labels=[]\n",
    "    for i in range(len(aug_pneumonia)):\n",
    "        aug_pneumonia_labels.append(2)\n",
    "    print(np.shape(aug_pneumonia),np.shape(aug_pneumonia_labels))  \n",
    "\n",
    "    full_data=[]\n",
    "    full_label=[]\n",
    "    for i in range(len(aug_normal)):\n",
    "        full_data.append(aug_normal[i])\n",
    "        full_label.append(aug_normal_labels[i])\n",
    "    for i in range(len(aug_covid)):\n",
    "        full_data.append(aug_covid[i])\n",
    "        full_label.append(aug_covid_labels[i])\n",
    "    for i in range(len(aug_pneumonia)):\n",
    "        full_data.append(aug_pneumonia[i])\n",
    "        full_label.append(aug_pneumonia_labels[i])\n",
    "        \n",
    "    full_data=np.array(full_data)\n",
    "    full_label=np.array(full_label)\n",
    "    \n",
    "    full_data=shuffle(full_data,random_state=0)\n",
    "    full_label=shuffle(full_label,random_state=0)\n",
    "    \n",
    "    return full_data,full_label\n",
    "\n",
    "\n",
    "    \n",
    "def making_training_and_testing_data(full_data,full_label):\n",
    "    \n",
    "    \n",
    "    train_label=[]\n",
    "    for i in range(len(full_label)):\n",
    "        if full_label[i]==0:\n",
    "            train_label.append([0,1,0])\n",
    "        elif full_label[i]==1:\n",
    "            train_label.append([1,0,0])\n",
    "        elif full_label[i]==2:\n",
    "\n",
    "            train_label.append([0,0,1])\n",
    "    full_label=np.array(train_label)\n",
    "    \n",
    "    return full_data,full_label\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':  #straight away go to this\n",
    "    normal_dir = \"/home/sriparna/s_sharma/expert_system_review_results/Test_data_final/Normal\" #give your normal cases data path here\n",
    "    #vit_datasets/Dataset_ViT/ViT_dataset/Covid-19\n",
    "    dir1 = os.path.join(normal_dir,\"*.png\")\n",
    "    dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
    "    dir = os.path.join(normal_dir,\"*.jpg\")\n",
    "    normal_files = glob.glob(dir)\n",
    "    normal_1 = glob.glob(dir1)\n",
    "    normal_2 = glob.glob(dir2)\n",
    "    normal_files.extend(normal_1)\n",
    "    normal_files.extend(normal_2)\n",
    "\n",
    "    normal_dir = \"/home/sriparna/s_sharma/expert_system_review_results/Test_data_final/Covid\"  #give your covid 19 cases data path here\n",
    "    dir1 = os.path.join(normal_dir,\"*.png\")\n",
    "    dir = os.path.join(normal_dir,\"*.jpg\")\n",
    "    dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
    "    covid_files = glob.glob(dir)\n",
    "    covid_files2 = glob.glob(dir2)\n",
    "    covid_files1 = glob.glob(dir1)\n",
    "    covid_files.extend(covid_files2)\n",
    "    covid_files.extend(covid_files1)\n",
    "\n",
    "    normal_dir = \"/home/sriparna/s_sharma/expert_system_review_results/Test_data_final/Pneumonia\" #give your pneumonia cases data path here\n",
    "    dir1 = os.path.join(normal_dir,\"*.png\")\n",
    "    dir2 = os.path.join(normal_dir,\"*.jpeg\")\n",
    "    dir = os.path.join(normal_dir,\"*.jpg\")\n",
    "    pneumonia_files = glob.glob(dir)\n",
    "    pneumonia_1 = glob.glob(dir1)\n",
    "    pneumonia_2 = glob.glob(dir2)\n",
    "    pneumonia_files.extend(pneumonia_1)\n",
    "    pneumonia_files.extend(pneumonia_2)\n",
    "\n",
    "    normal_files.sort()\n",
    "    covid_files.sort()\n",
    "    pneumonia_files.sort()\n",
    "    normal_files=shuffle(normal_files,random_state=10)\n",
    "    covid_files=shuffle(covid_files,random_state=10)\n",
    "    pneumonia_files=shuffle(pneumonia_files,random_state=10)\n",
    "    print(\"pneumonia_files:\",len(pneumonia_files))\n",
    "    print(\"covid_files:\",len(covid_files))\n",
    "    print(\"normal_files:\",len(normal_files))\n",
    "   \n",
    "    test_normal_files=normal_files\n",
    "    test_covid_files=covid_files\n",
    "    test_pneumonia_files=pneumonia_files\n",
    "    \n",
    "    \n",
    "    print(\"test normal:\",len(test_normal_files))\n",
    "    print(\"test covid:\",len(test_covid_files))\n",
    "    print(\"test pneumonia:\",len(test_pneumonia_files))\n",
    " \n",
    "    \n",
    "    test_aug_normal,test_aug_covid,test_aug_pneumonia=no_data_augmentation(test_normal_files,test_covid_files,test_pneumonia_files)\n",
    "    test_full_data,test_full_label=making_full_data(test_aug_normal,test_aug_covid,test_aug_pneumonia)\n",
    "    test_full_data,test_full_label=making_training_and_testing_data(test_full_data,test_full_label)\n",
    "    \n",
    "    if model_name==1:  #IT WILL RUN SE Inception v3 MODEL  \n",
    "        model1 = pickle.load(open('SE_Inception_v3_full_finetuning.sav', 'rb'))\n",
    "        test_data=np.stack((test_full_data,)*3,axis=-1)\n",
    "        model1.evaluate(test_data,test_full_label)\n",
    "        \n",
    "        model1 = pickle.load(open('SE_Inception_v3_partial finetuning.sav', 'rb'))\n",
    "        test_data=np.stack((test_full_data,)*3,axis=-1)\n",
    "        model1.evaluate(test_data,test_full_label)\n",
    "        \n",
    "        model1 = pickle.load(open('SE_Inception_v3_custom_finetuning.sav', 'rb'))\n",
    "        test_data=np.stack((test_full_data,)*3,axis=-1)\n",
    "        model1.evaluate(test_data,test_full_label)\n",
    "\n",
    "    elif model_name==2: #IT WILL RUN DENSENET201 MODEL\n",
    "      \n",
    "        model1 = pickle.load(open('DenseNet201_full_finetuning.sav', 'rb'))\n",
    "        test_data=test_full_data\n",
    "        model1.evaluate(test_data,test_full_label)\n",
    "        \n",
    "        model1 = pickle.load(open('DenseNet201_partial_finetuning.sav', 'rb'))\n",
    "        test_data=test_full_data\n",
    "        model1.evaluate(test_data,test_full_label)\n",
    "        \n",
    "        model1 = pickle.load(open('DenseNet201_custom_finetuning.sav', 'rb'))\n",
    "        test_data=np.stack((test_full_data,)*3,axis=-1)\n",
    "        model1.evaluate(test_data,test_full_label)\n",
    "    elif model_name==3: #IT WILL RUN SE SQUEEZENET MODEL\n",
    "        model1 = pickle.load(open('se_squeeznet_full_finetuning.sav', 'rb'))\n",
    "        test_data=test_full_data\n",
    "        model1.evaluate(test_data,test_full_label)\n",
    "        \n",
    "        model1 = pickle.load(open('se_squeeznet_partial_finetuning.sav', 'rb'))\n",
    "        test_data=test_full_data\n",
    "        model1.evaluate(test_data,test_full_label)\n",
    "        \n",
    "        model1 = pickle.load(open('se_squeeznet_custom_finetuning.sav', 'rb'))\n",
    "        test_data=test_full_data\n",
    "        model1.evaluate(test_data,test_full_label)\n",
    "    else:\n",
    "        print(\"Check your input model - only 1,2,3  are allowed\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abb45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
